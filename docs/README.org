#+TITLE: Minimum Cut problem
#+AUTHOR: Luca Zaninotto -- 2057074
#+DATE: 30 sept 2022
* The problem
  The problem we want to solve is to find a cut of a graph such that
  its weight is minimal. In other words, given a graph

  \[G = (V, E)\]

  where \(V = \{1,2,3,\dots,n\}\) a set of \(n\) vertices and \(E =
  \{(1,3), (4,6), \dots\}\) a set of \(m\) edges and a function

  \[ w : E \rightarrow \mathbb{R} \]

  a /cost/ function, that returns the weight of each node, we want to
  find

  \[p_1, p_2 \subseteq V \mid p_1 \cap p_2 = \emptyset \, , \, p_1 \cup p_2 = V\]

  such that

  \[\text{cost}(p_1, p_2) = \sum_{u \in p_1, v \in p_2} w((u,v))\]

  is minimized.
* Karger and Stein
  Karger and stein works by joining subsets of nodes, until only two
  remain. Those two are a cut of the graph. More in detail, given a
  Graph \(G = (V,E)\) where \(V = \{1,2,3,4,\dots,n\}\) is the set of
  vertices, the algorithm starts with a partition of \(V\) where each
  node appears by itself

  \[\{\{1\}, \{2\}, \{3\}, \dots \{n\}\}\]

  Then, let \(\mathcal{P}_a(V)\) be the set of partitions of \(V\), a
  =contraction= procedure joins two subsets and produces a new
  partition of \(V\).

  \[\text{contraction} : \mathcal{P}_a(V) \longrightarrow \mathcal{P}_a(V)\]

  This keeps happening, until the partition of \(V\) is made of only
  two sets \(p_1, p_2\). At this stage the sum of the weights that
  between the two nodes (the cut of the graph) is returned. This works
  because of the way in wich the =contraction= procedure selects the
  nodes to join in the partitions. The two nodes are selected based on
  a random selection based on the weight of the nodes. Nodes with an
  higher weight have an higher probability of being selected. This way
  the probability of ending up with the minimum cut of the graph lifts
  up from \(\frac{1}{2^n}\) to \(\frac{2}{n^2}\). This means that in
  order to have a sufficently high probability of picking the minimum
  cut of the graph we need to run the procedure \[\frac{n \dot
  \log(n)}{n-1}\] times.
  # Scrivere che il bound è stato ricacolato, in classe ne ha dato uno
  # più lasco
  
** Results
   #+attr_org: :width 500px
   #+attr_latex: :width 350px
   #+CAPTION: Karger and Stein run times against input size (number of vertices)
   [[../figs/Karger and Stein.png]]

   The function plotted is \(O(n^2\log^3(n))\) wich is the overall
   complexity of the algorithm. the coefficent is calculated as

   \[\max \left( \frac{t}{n^2\log^3(n)} \right) \]

   since the time of execution of the algorithm is maximized by this
   function and the different coefficent depend also on external
   factors (cpu throttle, memory allocations, etc.) and we're
   interested the behaviour of the algorithm against the input nodes.
* Stoer and Wagner
  Stoer and Wagner works in another way. Instead of relying on random
  cuts relies on the fact that given a couple of nodes, They either
  are separated by the minimum cut or are on the same side of the
  cut. So given a graph \(G=(V,E)\), \(s,t \in V\), an \(s,t\) minimum
  cut is a cut \((S,T)\) of \(G\) s.t.

  \[s\in S \vee t\in T\]
  \[w(S,T) \text{ is minimum among all \(s,t\) cuts}\]

  So, let \((S,T)\) be a global min-cut for \(G\). For every pair
  \(s,t \in V\) either \(s\in S\) and \(t\in T\) or \(s\) and \(t\)
  are on the same side of the cut.

  Stoer and wagner leverages this fact and searches for \(s,t \in V\)
  s.t. \((S, T)\) is a global min cut for \(G\). If that's also a
  global min-cut its weight is returned, otherwise the global min-cut
  for \(G\backslash\{s,t\}\) (The same graph as \(G\), where the nodes
  \(s\) and \(t\) are merged together) is also a global min-cut for
  \(G\).
** Results
   The complexity of this algorithm is

   \[O(mn * \log(n))\]

   where \(n = |V|\) and \(m = |E|\). so the coefficent for the plot
   is calculated again as

   \[\max \left( \frac{t}{mn\log(n)} \right)\]
   #+attr_org: :width 500px
   #+attr_latex: :width 350px
   #+CAPTION: Stoer and Wagner run times against input size (nodes and edges)
   [[../figs/Stoer and Wagner.png]]
* Hybrid approach
  An Hybrid approach consist into merging the two approaches (Karger
  and Stein and Stoer and Wagner) running Karger and Stein t times and
  then running Stoer and Wagner on the reulting graph allows to reduce
  the time? probabilmente no, karger and stein è parecchio lento.
** Results
   #+attr_org: :width 500px
   #+attr_latex: :width 350px
   #+CAPTION: Hybrid run times against input size (nodes and edges)
   [[../figs/Hybrid.png]]
* Results
** Karger and Stein vs Hybrid discovery time
** On efficency
